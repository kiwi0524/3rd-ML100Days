{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work\n",
    "1. 試比較有 BN 在 Batch_size = 2, 16, 32, 128, 256 下的差異\n",
    "2. 請嘗試將 BN 放在 Activation 之前，並比較訓練結果\n",
    "3. 請於 BN 放在 Input Layer 後，並比較結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "import itertools\n",
    "# Disable GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 資料前處理\n",
    "def preproc_x(x, flatten=True):\n",
    "    x = x / 255.\n",
    "    if flatten:\n",
    "        x = x.reshape((len(x), -1))\n",
    "    return x\n",
    "\n",
    "def preproc_y(y, num_classes=10):\n",
    "    if y.shape[-1] == 1:\n",
    "        y = keras.utils.to_categorical(y, num_classes)\n",
    "    return y    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = train\n",
    "x_test, y_test = test\n",
    "\n",
    "# Preproc the inputs\n",
    "x_train = preproc_x(x_train)\n",
    "x_test = preproc_x(x_test)\n",
    "\n",
    "# Preprc the outputs\n",
    "y_train = preproc_y(y_train)\n",
    "y_test = preproc_y(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import BatchNormalization\n",
    "\n",
    "\"\"\"\n",
    "建立神經網路，並加入 BN layer\n",
    "\"\"\"\n",
    "def build_mlp(input_shape, output_units=10, num_neurons=[512, 256, 128]):\n",
    "    \n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "    \n",
    "    for i, n_units in enumerate(num_neurons):\n",
    "        if i == 0:\n",
    "            x = keras.layers.Dense(units=n_units, \n",
    "                                   activation=\"relu\", \n",
    "                                   name=\"hidden_layer\"+str(i+1))(input_layer)\n",
    "            x = BatchNormalization()(x)\n",
    "        else:\n",
    "            x = keras.layers.Dense(units=n_units, \n",
    "                                   activation=\"relu\", \n",
    "                                   name=\"hidden_layer\"+str(i+1))(x)\n",
    "            x = BatchNormalization()(x)\n",
    "    \n",
    "    out = keras.layers.Dense(units=output_units, activation=\"softmax\", name=\"output\")(x)\n",
    "    \n",
    "    model = keras.models.Model(inputs=[input_layer], outputs=[out])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 超參數設定\n",
    "LEARNING_RATE = 1e-3\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = [2, 16, 32, 128, 256]\n",
    "MOMENTUM = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 291s 6ms/step - loss: 2.3016 - accuracy: 0.1490 - val_loss: 2.1493 - val_accuracy: 0.2210\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 301s 6ms/step - loss: 2.2342 - accuracy: 0.1669 - val_loss: 2.1565 - val_accuracy: 0.2107\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 305s 6ms/step - loss: 2.2370 - accuracy: 0.1651 - val_loss: 2.1680 - val_accuracy: 0.2131\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 307s 6ms/step - loss: 2.2359 - accuracy: 0.1648 - val_loss: 2.1518 - val_accuracy: 0.2085\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 305s 6ms/step - loss: 2.2357 - accuracy: 0.1664 - val_loss: 2.2276 - val_accuracy: 0.1969\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 306s 6ms/step - loss: 2.2333 - accuracy: 0.1681 - val_loss: 4.5965 - val_accuracy: 0.1993\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 305s 6ms/step - loss: 2.2330 - accuracy: 0.1693 - val_loss: 3.3193 - val_accuracy: 0.1948\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 305s 6ms/step - loss: 2.2322 - accuracy: 0.1692 - val_loss: 11.6476 - val_accuracy: 0.2133\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 304s 6ms/step - loss: 2.2245 - accuracy: 0.1758 - val_loss: 50.0623 - val_accuracy: 0.2011\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 305s 6ms/step - loss: 2.2232 - accuracy: 0.1741 - val_loss: 50.3388 - val_accuracy: 0.1897\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 305s 6ms/step - loss: 2.2285 - accuracy: 0.1733 - val_loss: 9.3570 - val_accuracy: 0.1848\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 304s 6ms/step - loss: 2.2251 - accuracy: 0.1743 - val_loss: 6.9602 - val_accuracy: 0.2199\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 304s 6ms/step - loss: 2.2256 - accuracy: 0.1684 - val_loss: 8.1615 - val_accuracy: 0.2161\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 301s 6ms/step - loss: 2.2257 - accuracy: 0.1726 - val_loss: 42.8053 - val_accuracy: 0.2228\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 301s 6ms/step - loss: 2.2280 - accuracy: 0.1685 - val_loss: 27.8867 - val_accuracy: 0.1998\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 302s 6ms/step - loss: 2.2320 - accuracy: 0.1645 - val_loss: 49.7274 - val_accuracy: 0.2144\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 302s 6ms/step - loss: 2.2370 - accuracy: 0.1647 - val_loss: 91.6922 - val_accuracy: 0.2004\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 301s 6ms/step - loss: 2.2383 - accuracy: 0.1625 - val_loss: 124.6959 - val_accuracy: 0.2175\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 303s 6ms/step - loss: 2.2390 - accuracy: 0.1617 - val_loss: 102.1928 - val_accuracy: 0.1976\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 299s 6ms/step - loss: 2.2420 - accuracy: 0.1564 - val_loss: 440.6295 - val_accuracy: 0.2073\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 298s 6ms/step - loss: 2.2466 - accuracy: 0.1617 - val_loss: 579.8763 - val_accuracy: 0.2060\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 297s 6ms/step - loss: 2.2479 - accuracy: 0.1614 - val_loss: 198.5076 - val_accuracy: 0.2062\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 297s 6ms/step - loss: 2.2485 - accuracy: 0.1582 - val_loss: 409.9517 - val_accuracy: 0.2141\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 298s 6ms/step - loss: 2.2457 - accuracy: 0.1629 - val_loss: 103.1867 - val_accuracy: 0.1956\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 298s 6ms/step - loss: 2.2487 - accuracy: 0.1554 - val_loss: 14.9869 - val_accuracy: 0.2210\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 297s 6ms/step - loss: 2.2579 - accuracy: 0.1558 - val_loss: 4.5595 - val_accuracy: 0.2133\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 297s 6ms/step - loss: 2.2580 - accuracy: 0.1526 - val_loss: 4.2869 - val_accuracy: 0.1803\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 296s 6ms/step - loss: 2.2591 - accuracy: 0.1522 - val_loss: 32.4698 - val_accuracy: 0.1923\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 297s 6ms/step - loss: 2.2634 - accuracy: 0.1510 - val_loss: 14.6654 - val_accuracy: 0.1921\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 297s 6ms/step - loss: 2.2586 - accuracy: 0.1524 - val_loss: 9.9003 - val_accuracy: 0.1865\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 298s 6ms/step - loss: 2.2594 - accuracy: 0.1518 - val_loss: 56.5301 - val_accuracy: 0.1900\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 298s 6ms/step - loss: 2.2606 - accuracy: 0.1533 - val_loss: 93.2601 - val_accuracy: 0.1961\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 297s 6ms/step - loss: 2.2591 - accuracy: 0.1526 - val_loss: 12.1078 - val_accuracy: 0.2000\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 298s 6ms/step - loss: 2.2604 - accuracy: 0.1531 - val_loss: 27.8207 - val_accuracy: 0.2089\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 297s 6ms/step - loss: 2.2608 - accuracy: 0.1520 - val_loss: 8.0059 - val_accuracy: 0.2083\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 296s 6ms/step - loss: 2.2612 - accuracy: 0.1499 - val_loss: 10.6400 - val_accuracy: 0.1978\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 297s 6ms/step - loss: 2.2575 - accuracy: 0.1519 - val_loss: 11.6554 - val_accuracy: 0.2199\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 297s 6ms/step - loss: 2.2567 - accuracy: 0.1504 - val_loss: 15.7560 - val_accuracy: 0.1946\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 297s 6ms/step - loss: 2.2578 - accuracy: 0.1502 - val_loss: 29.3052 - val_accuracy: 0.2089\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 299s 6ms/step - loss: 2.2581 - accuracy: 0.1511 - val_loss: 7.3137 - val_accuracy: 0.1784\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 302s 6ms/step - loss: 2.2610 - accuracy: 0.1496 - val_loss: 30.6276 - val_accuracy: 0.2145\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 303s 6ms/step - loss: 2.2584 - accuracy: 0.1499 - val_loss: 12.4365 - val_accuracy: 0.1555\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 302s 6ms/step - loss: 2.2574 - accuracy: 0.1497 - val_loss: 7.4326 - val_accuracy: 0.1834\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 303s 6ms/step - loss: 2.2587 - accuracy: 0.1503 - val_loss: 7.6005 - val_accuracy: 0.1772\n",
      "Epoch 45/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 297s 6ms/step - loss: 2.2594 - accuracy: 0.1486 - val_loss: 6.3230 - val_accuracy: 0.1681\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 297s 6ms/step - loss: 2.2579 - accuracy: 0.1540 - val_loss: 4.7947 - val_accuracy: 0.1886\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 297s 6ms/step - loss: 2.2596 - accuracy: 0.1488 - val_loss: 5.9696 - val_accuracy: 0.1903\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 296s 6ms/step - loss: 2.2588 - accuracy: 0.1514 - val_loss: 3.1533 - val_accuracy: 0.1875\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 297s 6ms/step - loss: 2.2581 - accuracy: 0.1510 - val_loss: 8.2114 - val_accuracy: 0.1703\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 297s 6ms/step - loss: 2.2627 - accuracy: 0.1523 - val_loss: 10.2539 - val_accuracy: 0.1895\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 39s 782us/step - loss: 1.8025 - accuracy: 0.3586 - val_loss: 1.6832 - val_accuracy: 0.4008\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 39s 777us/step - loss: 1.6513 - accuracy: 0.4137 - val_loss: 1.8891 - val_accuracy: 0.3433\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 39s 776us/step - loss: 1.6166 - accuracy: 0.4233 - val_loss: 1.6831 - val_accuracy: 0.3911\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 39s 777us/step - loss: 1.5772 - accuracy: 0.4370 - val_loss: 1.5589 - val_accuracy: 0.4340\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 39s 775us/step - loss: 1.5355 - accuracy: 0.4543 - val_loss: 1.4726 - val_accuracy: 0.4797\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 39s 776us/step - loss: 1.5053 - accuracy: 0.4654 - val_loss: 1.4706 - val_accuracy: 0.4720\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 39s 776us/step - loss: 1.4735 - accuracy: 0.4763 - val_loss: 1.4873 - val_accuracy: 0.4704\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 39s 777us/step - loss: 1.4432 - accuracy: 0.4854 - val_loss: 1.4179 - val_accuracy: 0.4948\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 39s 775us/step - loss: 1.4188 - accuracy: 0.4949 - val_loss: 1.4290 - val_accuracy: 0.4983\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 39s 776us/step - loss: 1.4147 - accuracy: 0.4978 - val_loss: 1.4399 - val_accuracy: 0.4866\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 39s 776us/step - loss: 1.3925 - accuracy: 0.5031 - val_loss: 1.4335 - val_accuracy: 0.4944\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 39s 776us/step - loss: 1.3740 - accuracy: 0.5136 - val_loss: 1.4520 - val_accuracy: 0.4839\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 39s 777us/step - loss: 1.3528 - accuracy: 0.5196 - val_loss: 1.3867 - val_accuracy: 0.5078\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 39s 778us/step - loss: 1.3362 - accuracy: 0.5253 - val_loss: 1.4134 - val_accuracy: 0.4996\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 39s 780us/step - loss: 1.3200 - accuracy: 0.5312 - val_loss: 1.4427 - val_accuracy: 0.4887\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 39s 776us/step - loss: 1.3145 - accuracy: 0.5345 - val_loss: 1.3660 - val_accuracy: 0.5112\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 39s 776us/step - loss: 1.3021 - accuracy: 0.5359 - val_loss: 1.3465 - val_accuracy: 0.5248\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 39s 778us/step - loss: 1.2911 - accuracy: 0.5406 - val_loss: 1.3670 - val_accuracy: 0.5159\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 39s 774us/step - loss: 1.2940 - accuracy: 0.5408 - val_loss: 1.3476 - val_accuracy: 0.5225\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 39s 776us/step - loss: 1.2782 - accuracy: 0.5467 - val_loss: 1.3318 - val_accuracy: 0.5293\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 39s 779us/step - loss: 1.2674 - accuracy: 0.5483 - val_loss: 1.3812 - val_accuracy: 0.5102\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 39s 778us/step - loss: 1.2622 - accuracy: 0.5523 - val_loss: 1.4289 - val_accuracy: 0.4933\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 39s 777us/step - loss: 1.2495 - accuracy: 0.5554 - val_loss: 1.3637 - val_accuracy: 0.5176\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 39s 775us/step - loss: 1.2332 - accuracy: 0.5610 - val_loss: 1.3639 - val_accuracy: 0.5245\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 39s 777us/step - loss: 1.2309 - accuracy: 0.5630 - val_loss: 1.3783 - val_accuracy: 0.5130\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 39s 776us/step - loss: 1.2217 - accuracy: 0.5679 - val_loss: 1.3716 - val_accuracy: 0.5122\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 39s 777us/step - loss: 1.2183 - accuracy: 0.5690 - val_loss: 1.3285 - val_accuracy: 0.5284\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 39s 775us/step - loss: 1.2074 - accuracy: 0.5730 - val_loss: 1.3510 - val_accuracy: 0.5294\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 39s 775us/step - loss: 1.1990 - accuracy: 0.5741 - val_loss: 1.3616 - val_accuracy: 0.5239\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 39s 778us/step - loss: 1.1961 - accuracy: 0.5747 - val_loss: 1.4145 - val_accuracy: 0.5037\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 39s 775us/step - loss: 1.1837 - accuracy: 0.5791 - val_loss: 1.3901 - val_accuracy: 0.5152\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 39s 776us/step - loss: 1.1811 - accuracy: 0.5802 - val_loss: 1.4032 - val_accuracy: 0.5118\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 39s 776us/step - loss: 1.2049 - accuracy: 0.5716 - val_loss: 1.3545 - val_accuracy: 0.5226\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 39s 776us/step - loss: 1.1797 - accuracy: 0.5815 - val_loss: 1.4386 - val_accuracy: 0.4995\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 39s 778us/step - loss: 1.1709 - accuracy: 0.5853 - val_loss: 1.4277 - val_accuracy: 0.4945\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 39s 776us/step - loss: 1.1593 - accuracy: 0.5893 - val_loss: 1.3340 - val_accuracy: 0.5338\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 39s 777us/step - loss: 1.1575 - accuracy: 0.5907 - val_loss: 1.3844 - val_accuracy: 0.5129\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 39s 779us/step - loss: 1.1569 - accuracy: 0.5889 - val_loss: 1.3620 - val_accuracy: 0.5236\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 39s 780us/step - loss: 1.1435 - accuracy: 0.5931 - val_loss: 1.3966 - val_accuracy: 0.5133\n",
      "Epoch 40/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 39s 774us/step - loss: 1.1530 - accuracy: 0.5901 - val_loss: 1.3510 - val_accuracy: 0.5249\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 39s 781us/step - loss: 1.1454 - accuracy: 0.5936 - val_loss: 1.3642 - val_accuracy: 0.5220\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 39s 772us/step - loss: 1.1399 - accuracy: 0.5960 - val_loss: 1.3416 - val_accuracy: 0.5321\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 39s 773us/step - loss: 1.1311 - accuracy: 0.5989 - val_loss: 1.4381 - val_accuracy: 0.4993\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 39s 773us/step - loss: 1.1299 - accuracy: 0.5983 - val_loss: 1.3605 - val_accuracy: 0.5234\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 39s 774us/step - loss: 1.1207 - accuracy: 0.6023 - val_loss: 1.3569 - val_accuracy: 0.5285\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 39s 773us/step - loss: 1.1152 - accuracy: 0.6031 - val_loss: 1.3983 - val_accuracy: 0.5171\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 39s 773us/step - loss: 1.1090 - accuracy: 0.6051 - val_loss: 1.3598 - val_accuracy: 0.5276\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 39s 772us/step - loss: 1.1103 - accuracy: 0.6052 - val_loss: 1.3388 - val_accuracy: 0.5349\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 39s 779us/step - loss: 1.1053 - accuracy: 0.6061 - val_loss: 1.4314 - val_accuracy: 0.4923\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 39s 774us/step - loss: 1.0983 - accuracy: 0.6111 - val_loss: 1.3348 - val_accuracy: 0.5352\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 21s 426us/step - loss: 1.7262 - accuracy: 0.3886 - val_loss: 1.5696 - val_accuracy: 0.4350\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 21s 419us/step - loss: 1.5368 - accuracy: 0.4554 - val_loss: 1.5027 - val_accuracy: 0.4654\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 21s 420us/step - loss: 1.4583 - accuracy: 0.4862 - val_loss: 1.5053 - val_accuracy: 0.4605\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 21s 420us/step - loss: 1.4127 - accuracy: 0.4995 - val_loss: 1.4925 - val_accuracy: 0.4691\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 21s 421us/step - loss: 1.3814 - accuracy: 0.5115 - val_loss: 1.4676 - val_accuracy: 0.4866\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 21s 420us/step - loss: 1.3471 - accuracy: 0.5235 - val_loss: 1.4777 - val_accuracy: 0.4787\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 21s 419us/step - loss: 1.3182 - accuracy: 0.5347 - val_loss: 1.4674 - val_accuracy: 0.4801\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 21s 418us/step - loss: 1.2952 - accuracy: 0.5407 - val_loss: 1.4577 - val_accuracy: 0.4904\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 21s 420us/step - loss: 1.2636 - accuracy: 0.5519 - val_loss: 1.4557 - val_accuracy: 0.4815\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 21s 420us/step - loss: 1.2462 - accuracy: 0.5562 - val_loss: 1.5216 - val_accuracy: 0.4629\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 21s 418us/step - loss: 1.2230 - accuracy: 0.5660 - val_loss: 1.5329 - val_accuracy: 0.4599\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 21s 419us/step - loss: 1.2084 - accuracy: 0.5699 - val_loss: 1.4570 - val_accuracy: 0.4897\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 21s 419us/step - loss: 1.1954 - accuracy: 0.5754 - val_loss: 1.4823 - val_accuracy: 0.4815\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 21s 419us/step - loss: 1.1717 - accuracy: 0.5860 - val_loss: 1.4273 - val_accuracy: 0.5019\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 21s 419us/step - loss: 1.1515 - accuracy: 0.5927 - val_loss: 1.4037 - val_accuracy: 0.5102\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 21s 420us/step - loss: 1.1370 - accuracy: 0.5992 - val_loss: 1.4558 - val_accuracy: 0.4916\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 21s 421us/step - loss: 1.1360 - accuracy: 0.5967 - val_loss: 1.4577 - val_accuracy: 0.4956\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 21s 419us/step - loss: 1.1182 - accuracy: 0.6020 - val_loss: 1.4238 - val_accuracy: 0.5077\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 21s 423us/step - loss: 1.1040 - accuracy: 0.6096 - val_loss: 1.3885 - val_accuracy: 0.5152\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 21s 420us/step - loss: 1.0882 - accuracy: 0.6123 - val_loss: 1.4164 - val_accuracy: 0.5150\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 21s 424us/step - loss: 1.0694 - accuracy: 0.6203 - val_loss: 1.3923 - val_accuracy: 0.5110\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 21s 418us/step - loss: 1.0603 - accuracy: 0.6202 - val_loss: 1.4314 - val_accuracy: 0.5109\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 21s 418us/step - loss: 1.0542 - accuracy: 0.6264 - val_loss: 1.3933 - val_accuracy: 0.5267\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 21s 418us/step - loss: 1.0319 - accuracy: 0.6355 - val_loss: 1.5048 - val_accuracy: 0.4853\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 21s 421us/step - loss: 1.0303 - accuracy: 0.6337 - val_loss: 1.4249 - val_accuracy: 0.5135\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 21s 420us/step - loss: 1.0304 - accuracy: 0.6345 - val_loss: 1.4609 - val_accuracy: 0.5085\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 21s 421us/step - loss: 1.0149 - accuracy: 0.6380 - val_loss: 1.4151 - val_accuracy: 0.5269\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 21s 423us/step - loss: 1.0000 - accuracy: 0.6448 - val_loss: 1.5001 - val_accuracy: 0.4994\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 21s 422us/step - loss: 0.9853 - accuracy: 0.6495 - val_loss: 1.4497 - val_accuracy: 0.5136\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 21s 422us/step - loss: 0.9725 - accuracy: 0.6545 - val_loss: 1.4978 - val_accuracy: 0.4931\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 21s 418us/step - loss: 0.9530 - accuracy: 0.6617 - val_loss: 1.4438 - val_accuracy: 0.5146\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 21s 420us/step - loss: 0.9429 - accuracy: 0.6649 - val_loss: 1.5012 - val_accuracy: 0.5076\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 22s 433us/step - loss: 0.9386 - accuracy: 0.6665 - val_loss: 1.5169 - val_accuracy: 0.4970\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 21s 420us/step - loss: 0.9193 - accuracy: 0.6746 - val_loss: 1.4751 - val_accuracy: 0.5154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 21s 418us/step - loss: 0.9153 - accuracy: 0.6769 - val_loss: 1.5126 - val_accuracy: 0.5026\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 21s 418us/step - loss: 0.9044 - accuracy: 0.6784 - val_loss: 1.4577 - val_accuracy: 0.5176\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 21s 416us/step - loss: 0.8913 - accuracy: 0.6819 - val_loss: 1.4779 - val_accuracy: 0.5163\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 21s 417us/step - loss: 0.8778 - accuracy: 0.6842 - val_loss: 1.4658 - val_accuracy: 0.5181\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 21s 417us/step - loss: 0.8721 - accuracy: 0.6871 - val_loss: 1.5017 - val_accuracy: 0.5084\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 21s 417us/step - loss: 0.8611 - accuracy: 0.6928 - val_loss: 1.5170 - val_accuracy: 0.5125\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 21s 417us/step - loss: 0.8581 - accuracy: 0.6946 - val_loss: 1.7211 - val_accuracy: 0.4698\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 21s 418us/step - loss: 0.8476 - accuracy: 0.6980 - val_loss: 1.6076 - val_accuracy: 0.4866\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 21s 418us/step - loss: 0.8424 - accuracy: 0.6981 - val_loss: 1.5185 - val_accuracy: 0.5132\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 21s 417us/step - loss: 0.8315 - accuracy: 0.7034 - val_loss: 1.5416 - val_accuracy: 0.5065\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 21s 417us/step - loss: 0.8347 - accuracy: 0.7039 - val_loss: 1.5538 - val_accuracy: 0.5061\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 21s 419us/step - loss: 0.8259 - accuracy: 0.7044 - val_loss: 1.5795 - val_accuracy: 0.5003\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 21s 418us/step - loss: 0.8184 - accuracy: 0.7083 - val_loss: 1.6048 - val_accuracy: 0.4939\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 21s 420us/step - loss: 0.7953 - accuracy: 0.7158 - val_loss: 1.5543 - val_accuracy: 0.5106\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 21s 417us/step - loss: 0.7971 - accuracy: 0.7142 - val_loss: 1.6223 - val_accuracy: 0.4973\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 21s 417us/step - loss: 0.8034 - accuracy: 0.7127 - val_loss: 1.6243 - val_accuracy: 0.5017\n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 1.7668 - accuracy: 0.3865 - val_loss: 1.6628 - val_accuracy: 0.4128\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 1.4997 - accuracy: 0.4714 - val_loss: 1.6474 - val_accuracy: 0.4200\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 8s 159us/step - loss: 1.3988 - accuracy: 0.5097 - val_loss: 1.5257 - val_accuracy: 0.4604\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 8s 159us/step - loss: 1.3235 - accuracy: 0.5347 - val_loss: 1.5020 - val_accuracy: 0.4783\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 1.2643 - accuracy: 0.5549 - val_loss: 1.4952 - val_accuracy: 0.4666\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 8s 159us/step - loss: 1.2122 - accuracy: 0.5755 - val_loss: 1.4975 - val_accuracy: 0.4831\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 8s 159us/step - loss: 1.1650 - accuracy: 0.5914 - val_loss: 1.5803 - val_accuracy: 0.4629\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 1.1230 - accuracy: 0.6063 - val_loss: 1.5256 - val_accuracy: 0.4719\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 1.0837 - accuracy: 0.6200 - val_loss: 1.4791 - val_accuracy: 0.4828\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 1.0528 - accuracy: 0.6292 - val_loss: 1.5577 - val_accuracy: 0.4753\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 1.0182 - accuracy: 0.6430 - val_loss: 1.6355 - val_accuracy: 0.4481\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 0.9838 - accuracy: 0.6541 - val_loss: 1.5720 - val_accuracy: 0.4571\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 0.9571 - accuracy: 0.6652 - val_loss: 1.6187 - val_accuracy: 0.4515\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 8s 157us/step - loss: 0.9172 - accuracy: 0.6784 - val_loss: 1.5840 - val_accuracy: 0.4685\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 0.8876 - accuracy: 0.6902 - val_loss: 1.6141 - val_accuracy: 0.4705\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 0.8588 - accuracy: 0.6983 - val_loss: 1.6064 - val_accuracy: 0.4759\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 8s 159us/step - loss: 0.8363 - accuracy: 0.7083 - val_loss: 1.6435 - val_accuracy: 0.4667\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 8s 159us/step - loss: 0.8076 - accuracy: 0.7170 - val_loss: 1.7046 - val_accuracy: 0.4602\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 0.7803 - accuracy: 0.7297 - val_loss: 1.7306 - val_accuracy: 0.4638\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 8s 159us/step - loss: 0.7466 - accuracy: 0.7389 - val_loss: 1.8052 - val_accuracy: 0.4396\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 0.7231 - accuracy: 0.7477 - val_loss: 1.7144 - val_accuracy: 0.4830\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 0.6965 - accuracy: 0.7564 - val_loss: 1.7243 - val_accuracy: 0.4701\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 8s 159us/step - loss: 0.6709 - accuracy: 0.7688 - val_loss: 1.8236 - val_accuracy: 0.4660\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 8s 157us/step - loss: 0.6563 - accuracy: 0.7709 - val_loss: 1.7706 - val_accuracy: 0.4698\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 0.6235 - accuracy: 0.7844 - val_loss: 1.8877 - val_accuracy: 0.4439\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 8s 159us/step - loss: 0.6033 - accuracy: 0.7892 - val_loss: 1.8912 - val_accuracy: 0.4504\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 0.5922 - accuracy: 0.7940 - val_loss: 1.8770 - val_accuracy: 0.4649\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 8s 159us/step - loss: 0.5676 - accuracy: 0.8018 - val_loss: 1.8023 - val_accuracy: 0.4816\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 0.5482 - accuracy: 0.8107 - val_loss: 2.0602 - val_accuracy: 0.4464\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 8s 158us/step - loss: 0.5356 - accuracy: 0.8131 - val_loss: 2.0763 - val_accuracy: 0.4492\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 8s 159us/step - loss: 0.5134 - accuracy: 0.8211 - val_loss: 2.0525 - val_accuracy: 0.4590\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 0.4929 - accuracy: 0.8298 - val_loss: 2.0034 - val_accuracy: 0.4683\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 0.4760 - accuracy: 0.8356 - val_loss: 2.2115 - val_accuracy: 0.4289\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 0.4622 - accuracy: 0.8380 - val_loss: 2.0239 - val_accuracy: 0.4749\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 8s 157us/step - loss: 0.4400 - accuracy: 0.8493 - val_loss: 2.0483 - val_accuracy: 0.4739\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 8s 159us/step - loss: 0.4255 - accuracy: 0.8539 - val_loss: 2.1116 - val_accuracy: 0.4748\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 0.4095 - accuracy: 0.8591 - val_loss: 2.2568 - val_accuracy: 0.4525\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 8s 157us/step - loss: 0.3870 - accuracy: 0.8668 - val_loss: 2.1511 - val_accuracy: 0.4669\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 0.3886 - accuracy: 0.8656 - val_loss: 2.2008 - val_accuracy: 0.4526\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 0.3807 - accuracy: 0.8703 - val_loss: 2.1702 - val_accuracy: 0.4836\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 0.3579 - accuracy: 0.8765 - val_loss: 2.2167 - val_accuracy: 0.4586\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 0.3533 - accuracy: 0.8773 - val_loss: 2.4455 - val_accuracy: 0.4329\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 0.3287 - accuracy: 0.8870 - val_loss: 2.5490 - val_accuracy: 0.4361\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 8s 157us/step - loss: 0.3279 - accuracy: 0.8862 - val_loss: 2.5777 - val_accuracy: 0.4408\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 8s 157us/step - loss: 0.3305 - accuracy: 0.8861 - val_loss: 2.4181 - val_accuracy: 0.4531\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 0.3032 - accuracy: 0.8969 - val_loss: 2.3199 - val_accuracy: 0.4809\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 0.2935 - accuracy: 0.9006 - val_loss: 2.4520 - val_accuracy: 0.4552\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 8s 159us/step - loss: 0.2817 - accuracy: 0.9029 - val_loss: 2.4518 - val_accuracy: 0.4649\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 0.2722 - accuracy: 0.9081 - val_loss: 2.5064 - val_accuracy: 0.4443\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 0.2600 - accuracy: 0.9120 - val_loss: 2.4820 - val_accuracy: 0.4569\n",
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 1.8611 - accuracy: 0.3602 - val_loss: 1.7536 - val_accuracy: 0.3824\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 1.5426 - accuracy: 0.4604 - val_loss: 1.5851 - val_accuracy: 0.4342\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 1.4391 - accuracy: 0.4956 - val_loss: 1.5325 - val_accuracy: 0.4615\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 1.3684 - accuracy: 0.5204 - val_loss: 1.5477 - val_accuracy: 0.4483\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 1.3128 - accuracy: 0.5407 - val_loss: 1.5130 - val_accuracy: 0.4679\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 1.2566 - accuracy: 0.5615 - val_loss: 1.4808 - val_accuracy: 0.4774\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 1.2119 - accuracy: 0.5774 - val_loss: 1.4661 - val_accuracy: 0.4861\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 1.1688 - accuracy: 0.5928 - val_loss: 1.4898 - val_accuracy: 0.4755\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 1.1289 - accuracy: 0.6080 - val_loss: 1.4760 - val_accuracy: 0.4813\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 1.0878 - accuracy: 0.6217 - val_loss: 1.5193 - val_accuracy: 0.4743\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 1.0518 - accuracy: 0.6336 - val_loss: 1.5318 - val_accuracy: 0.4694\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 1.0132 - accuracy: 0.6493 - val_loss: 1.4920 - val_accuracy: 0.4900\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 0.9818 - accuracy: 0.6597 - val_loss: 1.5386 - val_accuracy: 0.4784\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 0.9441 - accuracy: 0.6735 - val_loss: 1.4809 - val_accuracy: 0.4931\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 0.9096 - accuracy: 0.6861 - val_loss: 1.5416 - val_accuracy: 0.4784\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 0.8778 - accuracy: 0.6984 - val_loss: 1.5800 - val_accuracy: 0.4673\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 0.8469 - accuracy: 0.7104 - val_loss: 1.5518 - val_accuracy: 0.4881\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 0.8143 - accuracy: 0.7217 - val_loss: 1.5405 - val_accuracy: 0.4852\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 0.7843 - accuracy: 0.7352 - val_loss: 1.6669 - val_accuracy: 0.4746\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 0.7552 - accuracy: 0.7421 - val_loss: 1.7205 - val_accuracy: 0.4548\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 0.7246 - accuracy: 0.7555 - val_loss: 1.6331 - val_accuracy: 0.4790\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 0.6996 - accuracy: 0.7627 - val_loss: 1.8018 - val_accuracy: 0.4626\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 6s 113us/step - loss: 0.6731 - accuracy: 0.7737 - val_loss: 1.7946 - val_accuracy: 0.4568\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 6s 113us/step - loss: 0.6378 - accuracy: 0.7858 - val_loss: 1.7420 - val_accuracy: 0.4734\n",
      "Epoch 25/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 6s 112us/step - loss: 0.6101 - accuracy: 0.7962 - val_loss: 1.7660 - val_accuracy: 0.4688\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 6s 113us/step - loss: 0.5880 - accuracy: 0.8036 - val_loss: 1.7515 - val_accuracy: 0.4817\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 6s 110us/step - loss: 0.5617 - accuracy: 0.8130 - val_loss: 1.9225 - val_accuracy: 0.4470\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 0.5361 - accuracy: 0.8239 - val_loss: 1.9122 - val_accuracy: 0.4675\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 0.5077 - accuracy: 0.8344 - val_loss: 1.8366 - val_accuracy: 0.4717\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 0.4910 - accuracy: 0.8409 - val_loss: 1.8358 - val_accuracy: 0.4818\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 0.4633 - accuracy: 0.8512 - val_loss: 1.8727 - val_accuracy: 0.4755\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 0.4442 - accuracy: 0.8566 - val_loss: 2.0059 - val_accuracy: 0.4611\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 0.4222 - accuracy: 0.8652 - val_loss: 2.0478 - val_accuracy: 0.4675\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 6s 110us/step - loss: 0.4078 - accuracy: 0.8705 - val_loss: 2.0645 - val_accuracy: 0.4722\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 0.3833 - accuracy: 0.8794 - val_loss: 1.9771 - val_accuracy: 0.4744\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 6s 110us/step - loss: 0.3612 - accuracy: 0.8856 - val_loss: 2.1417 - val_accuracy: 0.4695\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 0.3502 - accuracy: 0.8908 - val_loss: 2.1123 - val_accuracy: 0.4665\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 0.3296 - accuracy: 0.8975 - val_loss: 2.1590 - val_accuracy: 0.4729\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 0.3125 - accuracy: 0.9039 - val_loss: 2.0989 - val_accuracy: 0.4823\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 0.3075 - accuracy: 0.9050 - val_loss: 2.2465 - val_accuracy: 0.4694\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 6s 110us/step - loss: 0.2962 - accuracy: 0.9089 - val_loss: 2.3057 - val_accuracy: 0.4616\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 0.2686 - accuracy: 0.9201 - val_loss: 2.2504 - val_accuracy: 0.4614\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 0.2529 - accuracy: 0.9252 - val_loss: 2.4200 - val_accuracy: 0.4468\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 6s 110us/step - loss: 0.2455 - accuracy: 0.9272 - val_loss: 2.3358 - val_accuracy: 0.4681\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 0.2280 - accuracy: 0.9346 - val_loss: 2.4687 - val_accuracy: 0.4585\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 6s 110us/step - loss: 0.2136 - accuracy: 0.9384 - val_loss: 2.3021 - val_accuracy: 0.4770\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 0.2008 - accuracy: 0.9438 - val_loss: 2.4355 - val_accuracy: 0.4744\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 0.1896 - accuracy: 0.9475 - val_loss: 2.4266 - val_accuracy: 0.4672\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 6s 110us/step - loss: 0.1806 - accuracy: 0.9505 - val_loss: 2.5357 - val_accuracy: 0.4554\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 0.1750 - accuracy: 0.9521 - val_loss: 2.4160 - val_accuracy: 0.4745\n"
     ]
    }
   ],
   "source": [
    "# Define results\n",
    "results = {}\n",
    "for batchSize in BATCH_SIZE :\n",
    "    \n",
    "    model = build_mlp(input_shape=x_train.shape[1:])\n",
    "    model.summary()\n",
    "\n",
    "    optimizer = keras.optimizers.SGD(lr=LEARNING_RATE, nesterov=True, momentum=MOMENTUM)\n",
    "    model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)\n",
    "\n",
    "    model.fit(x_train, y_train, \n",
    "              epochs=EPOCHS, \n",
    "              \n",
    "              # different batch_size\n",
    "              batch_size=batchSize, \n",
    "              \n",
    "              validation_data=(x_test, y_test), \n",
    "              shuffle=True)\n",
    "\n",
    "    # Collect results\n",
    "    train_loss = model.history.history[\"loss\"]\n",
    "    valid_loss = model.history.history[\"val_loss\"]\n",
    "    train_acc = model.history.history[\"accuracy\"]\n",
    "    valid_acc = model.history.history[\"val_accuracy\"]\n",
    "    \n",
    "    name_tag = 'batchSize : %.2f' % batchSize\n",
    "    results[name_tag] = {'train-loss': train_loss,\n",
    "                         'valid-loss': valid_loss,\n",
    "                         'train-acc' : train_acc,\n",
    "                         'valid-acc' : valid_acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "    # plot\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline\n",
    "\n",
    "    plt.plot(range(len(train_loss)), train_loss, label=\"train loss\")\n",
    "    plt.plot(range(len(valid_loss)), valid_loss, label=\"valid loss\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Loss\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(range(len(train_acc)), train_acc, label=\"train accuracy\")\n",
    "    plt.plot(range(len(valid_acc)), valid_acc, label=\"valid accuracy\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Accuracy\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import keras\n",
    "import itertools\n",
    "# Disable GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "train, test = keras.datasets.cifar10.load_data()\n",
    "\n",
    "## 資料前處理\n",
    "def preproc_x(x, flatten=True):\n",
    "    x = x / 255.\n",
    "    if flatten:\n",
    "        x = x.reshape((len(x), -1))\n",
    "    return x\n",
    "\n",
    "def preproc_y(y, num_classes=10):\n",
    "    if y.shape[-1] == 1:\n",
    "        y = keras.utils.to_categorical(y, num_classes)\n",
    "    return y    \n",
    "\n",
    "x_train, y_train = train\n",
    "x_test, y_test = test\n",
    "\n",
    "# Preproc the inputs\n",
    "x_train = preproc_x(x_train)\n",
    "x_test = preproc_x(x_test)\n",
    "\n",
    "# Preprc the outputs\n",
    "y_train = preproc_y(y_train)\n",
    "y_test = preproc_y(y_test)\n",
    "\n",
    "\n",
    "from keras.layers import BatchNormalization\n",
    "\n",
    "\"\"\"\n",
    "建立神經網路，並加入 BN layer\n",
    "\"\"\"\n",
    "def build_mlp(input_shape, output_units=10, num_neurons=[512, 256, 128]):\n",
    "    \n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "    \n",
    "    for i, n_units in enumerate(num_neurons):\n",
    "        if i == 0:\n",
    "            # 2. 把 BatchNormalization 放在 activation 前\n",
    "            x = BatchNormalization()(input_layer)\n",
    "            \n",
    "            x = keras.layers.Dense(units=n_units, \n",
    "                                   activation=\"relu\", \n",
    "                                   name=\"hidden_layer\"+str(i+1))(x)\n",
    "        else:\n",
    "            # 2. 把 BatchNormalization 放在 activation 前\n",
    "            x = BatchNormalization()(x)\n",
    "            \n",
    "            x = keras.layers.Dense(units=n_units, \n",
    "                                   activation=\"relu\", \n",
    "                                   name=\"hidden_layer\"+str(i+1))(x)\n",
    "    \n",
    "    out = keras.layers.Dense(units=output_units, activation=\"softmax\", name=\"output\")(x)\n",
    "    \n",
    "    model = keras.models.Model(inputs=[input_layer], outputs=[out])\n",
    "    return model\n",
    "\n",
    "\n",
    "## 超參數設定\n",
    "LEARNING_RATE = 1e-3\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 512\n",
    "MOMENTUM = 0.95\n",
    "results = {}\n",
    "for batchSize in BATCH_SIZE :\n",
    "    \n",
    "    model = build_mlp(input_shape=x_train.shape[1:])\n",
    "    model.summary()\n",
    "\n",
    "    optimizer = keras.optimizers.SGD(lr=LEARNING_RATE, nesterov=True, momentum=MOMENTUM)\n",
    "    model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)\n",
    "\n",
    "    model.fit(x_train, y_train, \n",
    "              epochs=EPOCHS, \n",
    "              \n",
    "              # different batch_size\n",
    "              batch_size=batchSize, \n",
    "              \n",
    "              validation_data=(x_test, y_test), \n",
    "              shuffle=True)\n",
    "\n",
    "    # Collect results\n",
    "    train_loss = model.history.history[\"loss\"]\n",
    "    valid_loss = model.history.history[\"val_loss\"]\n",
    "    train_acc = model.history.history[\"accuracy\"]\n",
    "    valid_acc = model.history.history[\"val_accuracy\"]\n",
    "    \n",
    "    name_tag = 'batchSize : %.2f' % batchSize\n",
    "    results[name_tag] = {'train-loss': train_loss,\n",
    "                         'valid-loss': valid_loss,\n",
    "                         'train-acc' : train_acc,\n",
    "                         'valid-acc' : valid_acc}\n",
    "model = build_mlp(input_shape=x_train.shape[1:])\n",
    "model.summary()\n",
    "\n",
    "optimizer = keras.optimizers.SGD(lr=LEARNING_RATE, nesterov=True, momentum=MOMENTUM)\n",
    "model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)\n",
    "\n",
    "model.fit(x_train, y_train, \n",
    "          epochs=EPOCHS, \n",
    "          batch_size=BATCH_SIZE, \n",
    "          validation_data=(x_test, y_test), \n",
    "          shuffle=True)\n",
    "\n",
    "# Collect results\n",
    "train_loss_before = model.history.history[\"loss\"]\n",
    "valid_loss_before = model.history.history[\"val_loss\"]\n",
    "train_acc_before = model.history.history[\"acc\"]\n",
    "valid_acc_before = model.history.history[\"val_acc\"]\n",
    "   \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define results\n",
    "results = {}\n",
    "for batchSize in BATCH_SIZE :\n",
    "    \n",
    "    model = build_mlp(input_shape=x_train.shape[1:])\n",
    "    model.summary()\n",
    "\n",
    "    optimizer = keras.optimizers.SGD(lr=LEARNING_RATE, nesterov=True, momentum=MOMENTUM)\n",
    "    model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)\n",
    "\n",
    "    model.fit(x_train, y_train, \n",
    "              epochs=EPOCHS, \n",
    "              \n",
    "              # different batch_size\n",
    "              batch_size=batchSize, \n",
    "              \n",
    "              validation_data=(x_test, y_test), \n",
    "              shuffle=True)\n",
    "\n",
    "    # Collect results\n",
    "    train_loss = model.history.history[\"loss\"]\n",
    "    valid_loss = model.history.history[\"val_loss\"]\n",
    "    train_acc = model.history.history[\"accuracy\"]\n",
    "    valid_acc = model.history.history[\"val_accuracy\"]\n",
    "    \n",
    "    name_tag = 'batchSize : %.2f' % batchSize\n",
    "    results[name_tag] = {'train-loss': train_loss,\n",
    "                         'valid-loss': valid_loss,\n",
    "                         'train-acc' : train_acc,\n",
    "                         'valid-acc' : valid_acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(range(len(train_loss)), train_loss, label=\"train loss\")\n",
    "plt.plot(range(len(valid_loss)), valid_loss, label=\"valid loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Loss\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(len(train_acc)), train_acc, label=\"train accuracy\")\n",
    "plt.plot(range(len(valid_acc)), valid_acc, label=\"valid accuracy\")\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
